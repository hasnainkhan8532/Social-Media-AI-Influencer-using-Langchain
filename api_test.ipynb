{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb2efbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciao!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# Suppress urllib3 SSL warnings\n",
    "warnings.filterwarnings('ignore', message='urllib3 v2 only supports OpenSSL 1.1.1+')\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Check if GOOGLE_API_KEY is available, if not prompt for it\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "    import getpass\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "model = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(content=\"hi!\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9535059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Testing OpenAI API Integration...\n",
      "🔄 Initializing OpenAI model...\n",
      "✅ OpenAI model initialized successfully!\n",
      "🔄 Sending test message to OpenAI...\n",
      "✅ OpenAI API test successful!\n",
      "🤖 OpenAI Response: Hello! One interesting fact about AI is that it can be used to help predict and prevent wildfires by analyzing data such as weather patterns and vegetation health.\n"
     ]
    }
   ],
   "source": [
    "# OpenAI API Key Test\n",
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "print(\"🤖 Testing OpenAI API Integration...\")\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore', message='urllib3 v2 only supports OpenSSL 1.1.1+')\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Check if OPENAI_API_KEY is available\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai_api_key or openai_api_key == \"your_openai_api_key_here\":\n",
    "    print(\"⚠️  OpenAI API key not found or using placeholder value.\")\n",
    "    print(\"📝 To use OpenAI:\")\n",
    "    print(\"   1. Get API key from: https://platform.openai.com/api-keys\")\n",
    "    print(\"   2. Add to .env file: OPENAI_API_KEY=your_actual_key\")\n",
    "    print(\"   3. Restart notebook kernel\")\n",
    "    \n",
    "    # Prompt for API key\n",
    "    import getpass\n",
    "    manual_key = getpass.getpass(\"Enter OpenAI API key (or press Enter to skip): \")\n",
    "    if manual_key.strip():\n",
    "        os.environ[\"OPENAI_API_KEY\"] = manual_key\n",
    "        openai_api_key = manual_key\n",
    "    else:\n",
    "        print(\"⏭️  Skipping OpenAI test...\")\n",
    "        openai_api_key = None\n",
    "\n",
    "if openai_api_key:\n",
    "    try:\n",
    "        print(\"🔄 Initializing OpenAI model...\")\n",
    "        \n",
    "        # Initialize OpenAI model using LangChain\n",
    "        openai_model = init_chat_model(\"gpt-3.5-turbo\", model_provider=\"openai\")\n",
    "        \n",
    "        print(\"✅ OpenAI model initialized successfully!\")\n",
    "        \n",
    "        # Test with a simple message\n",
    "        messages = [\n",
    "            SystemMessage(content=\"You are a helpful assistant that responds concisely.\"),\n",
    "            HumanMessage(content=\"Say hello and tell me one interesting fact about AI.\"),\n",
    "        ]\n",
    "        \n",
    "        print(\"🔄 Sending test message to OpenAI...\")\n",
    "        response = openai_model.invoke(messages)\n",
    "        \n",
    "        print(\"✅ OpenAI API test successful!\")\n",
    "        print(f\"🤖 OpenAI Response: {response.content}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ OpenAI API test failed: {str(e)}\")\n",
    "        print(\"🔍 Possible issues:\")\n",
    "        print(\"   - Invalid API key\")\n",
    "        print(\"   - Insufficient credits/quota\")\n",
    "        print(\"   - Network connectivity issues\")\n",
    "        print(\"   - API key doesn't have access to GPT models\")\n",
    "        \n",
    "        # Show first few characters of API key for debugging\n",
    "        if openai_api_key:\n",
    "            masked_key = openai_api_key[:8] + \"...\" + openai_api_key[-4:] if len(openai_api_key) > 12 else \"***\"\n",
    "            print(f\"   - Using API key: {masked_key}\")\n",
    "else:\n",
    "    print(\"⏭️  OpenAI test skipped - no API key provided.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71216aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔀 Comparing Google Gemini and OpenAI responses...\n",
      "🔄 Testing Google Gemini...\n",
      "✅ Google Gemini response received\n",
      "🔄 Testing OpenAI...\n",
      "✅ OpenAI response received\n",
      "\n",
      "📝 Question: Explain what machine learning is in exactly 2 sentences.\n",
      "============================================================\n",
      "\n",
      "🤖 Google Gemini:\n",
      "   Machine learning is a subset of artificial intelligence that enables systems to learn from data, identify patterns, and make decisions or predictions with minimal human intervention. It uses algorithms to analyze data, build models, and then apply those models to new data to perform specific tasks.\n",
      "----------------------------------------\n",
      "\n",
      "🤖 OpenAI GPT-3.5:\n",
      "   Machine learning is a subfield of artificial intelligence that involves developing algorithms and statistical models that enable computers to learn from and make predictions or decisions based on data. It aims to allow computers to automatically learn and improve from experience without being explicitly programmed.\n",
      "----------------------------------------\n",
      "\n",
      "📊 Summary:\n",
      "   - Google Gemini: ✅ Working\n",
      "   - OpenAI GPT-3.5: ✅ Working\n",
      "   - Total working models: 2/2\n"
     ]
    }
   ],
   "source": [
    "# API Comparison: Google Gemini vs OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "print(\"🔀 Comparing Google Gemini and OpenAI responses...\")\n",
    "load_dotenv()\n",
    "\n",
    "# Test prompt\n",
    "test_prompt = \"Explain what machine learning is in exactly 2 sentences.\"\n",
    "\n",
    "# Test both APIs if available\n",
    "google_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Test Google Gemini\n",
    "if google_key and google_key != \"your_actual_api_key_here\":\n",
    "    try:\n",
    "        print(\"🔄 Testing Google Gemini...\")\n",
    "        google_model = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")\n",
    "        messages = [\n",
    "            SystemMessage(content=\"You are a helpful assistant. Be precise and concise.\"),\n",
    "            HumanMessage(content=test_prompt)\n",
    "        ]\n",
    "        google_response = google_model.invoke(messages)\n",
    "        results['Google Gemini'] = google_response.content\n",
    "        print(\"✅ Google Gemini response received\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Google Gemini failed: {str(e)}\")\n",
    "        results['Google Gemini'] = f\"Error: {str(e)}\"\n",
    "else:\n",
    "    results['Google Gemini'] = \"⚠️ API key not configured\"\n",
    "\n",
    "# Test OpenAI\n",
    "if openai_key and openai_key != \"your_openai_api_key_here\":\n",
    "    try:\n",
    "        print(\"🔄 Testing OpenAI...\")\n",
    "        openai_model = init_chat_model(\"gpt-3.5-turbo\", model_provider=\"openai\")\n",
    "        messages = [\n",
    "            SystemMessage(content=\"You are a helpful assistant. Be precise and concise.\"),\n",
    "            HumanMessage(content=test_prompt)\n",
    "        ]\n",
    "        openai_response = openai_model.invoke(messages)\n",
    "        results['OpenAI GPT-3.5'] = openai_response.content\n",
    "        print(\"✅ OpenAI response received\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ OpenAI failed: {str(e)}\")\n",
    "        results['OpenAI GPT-3.5'] = f\"Error: {str(e)}\"\n",
    "else:\n",
    "    results['OpenAI GPT-3.5'] = \"⚠️ API key not configured\"\n",
    "\n",
    "# Display results\n",
    "print(f\"\\n📝 Question: {test_prompt}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for model_name, response in results.items():\n",
    "    print(f\"\\n🤖 {model_name}:\")\n",
    "    print(f\"   {response}\")\n",
    "    print(\"-\"*40)\n",
    "\n",
    "print(f\"\\n📊 Summary:\")\n",
    "print(f\"   - Google Gemini: {'✅ Working' if 'Error' not in results['Google Gemini'] and '⚠️' not in results['Google Gemini'] else '❌ Failed'}\")\n",
    "print(f\"   - OpenAI GPT-3.5: {'✅ Working' if 'Error' not in results['OpenAI GPT-3.5'] and '⚠️' not in results['OpenAI GPT-3.5'] else '❌ Failed'}\")\n",
    "\n",
    "working_models = [k for k, v in results.items() if 'Error' not in v and '⚠️' not in v]\n",
    "print(f\"   - Total working models: {len(working_models)}/{len(results)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
